{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1351797,"sourceType":"datasetVersion","datasetId":786787}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-16T18:14:31.223892Z","iopub.execute_input":"2025-05-16T18:14:31.224154Z","iopub.status.idle":"2025-05-16T18:14:31.228417Z","shell.execute_reply.started":"2025-05-16T18:14:31.224135Z","shell.execute_reply":"2025-05-16T18:14:31.227590Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T18:04:08.197071Z","iopub.execute_input":"2025-05-16T18:04:08.197543Z","iopub.status.idle":"2025-05-16T18:04:08.201779Z","shell.execute_reply.started":"2025-05-16T18:04:08.197521Z","shell.execute_reply":"2025-05-16T18:04:08.201023Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"BATCH_SIZE = 64\nNUM_EPOCHS = 50\nLEARNING_RATE = 0.001","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T18:04:11.171979Z","iopub.execute_input":"2025-05-16T18:04:11.172716Z","iopub.status.idle":"2025-05-16T18:04:11.175997Z","shell.execute_reply.started":"2025-05-16T18:04:11.172688Z","shell.execute_reply":"2025-05-16T18:04:11.175209Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Grayscale(),\n    transforms.Resize((48, 48)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T18:14:36.959498Z","iopub.execute_input":"2025-05-16T18:14:36.959781Z","iopub.status.idle":"2025-05-16T18:14:36.964049Z","shell.execute_reply.started":"2025-05-16T18:14:36.959762Z","shell.execute_reply":"2025-05-16T18:14:36.963468Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"train_dataset = datasets.ImageFolder(\"/kaggle/input/fer2013/train\", transform=transform)\nval_dataset   = datasets.ImageFolder(\"/kaggle/input/fer2013/test\", transform=transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\nval_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n\n# Residual Block\ntorch.manual_seed(42)\nclass ResidualBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, dropout_prob=0.3):\n        super().__init__()\n        self.shortcut = nn.Conv2d(in_channels, out_channels, kernel_size=1, padding=0)\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n        self.bn1   = nn.BatchNorm2d(out_channels)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n        self.bn2   = nn.BatchNorm2d(out_channels)\n        self.pool  = nn.MaxPool2d(2,2)\n        self.drop  = nn.Dropout2d(dropout_prob)\n\n    def forward(self, x):\n        s = self.shortcut(x)\n        y = F.relu(self.bn1(self.conv1(x)))\n        y = self.bn2(self.conv2(y))\n        out = F.relu(s + y)\n        out = self.pool(out)\n        return self.drop(out)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T18:14:39.464991Z","iopub.execute_input":"2025-05-16T18:14:39.465283Z","iopub.status.idle":"2025-05-16T18:15:14.177580Z","shell.execute_reply.started":"2025-05-16T18:14:39.465261Z","shell.execute_reply":"2025-05-16T18:15:14.177001Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"class EmotionCNN(nn.Module):\n    def __init__(self, num_classes=7):\n        super().__init__()\n        self.rb1 = ResidualBlock(1,  32)\n        self.rb2 = ResidualBlock(32, 64)\n        self.rb3 = ResidualBlock(64, 128)\n        self.rb4 = ResidualBlock(128,256)\n        self.global_pool = nn.AdaptiveAvgPool2d((1,1))\n        self.fc1 = nn.Linear(256, 128)\n        self.bn_fc = nn.BatchNorm1d(128)\n        self.drop_fc = nn.Dropout(0.5)\n        self.out = nn.Linear(128, num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n                nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n                if m.bias is not None:\n                    nn.init.zeros_(m.bias)\n\n    def forward(self, x):\n        x = self.rb1(x)\n        x = self.rb2(x)\n        x = self.rb3(x)\n        x = self.rb4(x)\n        x = self.global_pool(x)\n        x = x.view(x.size(0), -1)\n        x = F.relu(self.bn_fc(self.fc1(x)))\n        x = self.drop_fc(x)\n        return self.out(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T18:15:17.819769Z","iopub.execute_input":"2025-05-16T18:15:17.820307Z","iopub.status.idle":"2025-05-16T18:15:17.827258Z","shell.execute_reply.started":"2025-05-16T18:15:17.820284Z","shell.execute_reply":"2025-05-16T18:15:17.826438Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"model = EmotionCNN(num_classes=7).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T18:15:23.306232Z","iopub.execute_input":"2025-05-16T18:15:23.306478Z","iopub.status.idle":"2025-05-16T18:15:23.510889Z","shell.execute_reply.started":"2025-05-16T18:15:23.306461Z","shell.execute_reply":"2025-05-16T18:15:23.510318Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"for epoch in range(NUM_EPOCHS):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        _, predicted = outputs.max(1)\n        total += labels.size(0)\n        correct += predicted.eq(labels).sum().item()\n\n    train_acc = 100. * correct / total\n    avg_loss = running_loss / len(train_loader)\n    print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}]  Loss: {avg_loss:.4f}  Accuracy: {train_acc:.2f}%\")\n\n# Save model\ntorch.save(model.state_dict(), \"emotion_cnn_resnet.pt\")\nprint(\"\\nModel saved as emotion_cnn_resnet.pt\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T18:15:27.283834Z","iopub.execute_input":"2025-05-16T18:15:27.284405Z","iopub.status.idle":"2025-05-16T18:53:49.365703Z","shell.execute_reply.started":"2025-05-16T18:15:27.284380Z","shell.execute_reply":"2025-05-16T18:53:49.365033Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/50]  Loss: 2.0431  Accuracy: 20.09%\nEpoch [2/50]  Loss: 1.8384  Accuracy: 23.32%\nEpoch [3/50]  Loss: 1.8004  Accuracy: 25.08%\nEpoch [4/50]  Loss: 1.7882  Accuracy: 25.73%\nEpoch [5/50]  Loss: 1.7651  Accuracy: 27.11%\nEpoch [6/50]  Loss: 1.6961  Accuracy: 30.59%\nEpoch [7/50]  Loss: 1.5487  Accuracy: 39.17%\nEpoch [8/50]  Loss: 1.4590  Accuracy: 43.69%\nEpoch [9/50]  Loss: 1.3946  Accuracy: 46.31%\nEpoch [10/50]  Loss: 1.3460  Accuracy: 48.63%\nEpoch [11/50]  Loss: 1.3099  Accuracy: 49.95%\nEpoch [12/50]  Loss: 1.2806  Accuracy: 51.33%\nEpoch [13/50]  Loss: 1.2577  Accuracy: 51.69%\nEpoch [14/50]  Loss: 1.2310  Accuracy: 53.20%\nEpoch [15/50]  Loss: 1.2218  Accuracy: 53.59%\nEpoch [16/50]  Loss: 1.1966  Accuracy: 54.84%\nEpoch [17/50]  Loss: 1.1838  Accuracy: 54.76%\nEpoch [18/50]  Loss: 1.1678  Accuracy: 55.59%\nEpoch [19/50]  Loss: 1.1607  Accuracy: 56.13%\nEpoch [20/50]  Loss: 1.1502  Accuracy: 56.30%\nEpoch [21/50]  Loss: 1.1399  Accuracy: 57.09%\nEpoch [22/50]  Loss: 1.1266  Accuracy: 57.68%\nEpoch [23/50]  Loss: 1.1161  Accuracy: 58.03%\nEpoch [24/50]  Loss: 1.1055  Accuracy: 58.09%\nEpoch [25/50]  Loss: 1.1015  Accuracy: 58.19%\nEpoch [26/50]  Loss: 1.0978  Accuracy: 58.58%\nEpoch [27/50]  Loss: 1.0876  Accuracy: 59.01%\nEpoch [28/50]  Loss: 1.0790  Accuracy: 59.30%\nEpoch [29/50]  Loss: 1.0684  Accuracy: 59.86%\nEpoch [30/50]  Loss: 1.0628  Accuracy: 60.08%\nEpoch [31/50]  Loss: 1.0579  Accuracy: 60.33%\nEpoch [32/50]  Loss: 1.0488  Accuracy: 60.55%\nEpoch [33/50]  Loss: 1.0496  Accuracy: 60.68%\nEpoch [34/50]  Loss: 1.0331  Accuracy: 61.20%\nEpoch [35/50]  Loss: 1.0362  Accuracy: 60.98%\nEpoch [36/50]  Loss: 1.0242  Accuracy: 61.44%\nEpoch [37/50]  Loss: 1.0221  Accuracy: 61.59%\nEpoch [38/50]  Loss: 1.0132  Accuracy: 61.96%\nEpoch [39/50]  Loss: 1.0093  Accuracy: 61.94%\nEpoch [40/50]  Loss: 1.0002  Accuracy: 62.42%\nEpoch [41/50]  Loss: 0.9977  Accuracy: 62.75%\nEpoch [42/50]  Loss: 0.9935  Accuracy: 62.55%\nEpoch [43/50]  Loss: 0.9867  Accuracy: 62.77%\nEpoch [44/50]  Loss: 0.9841  Accuracy: 63.11%\nEpoch [45/50]  Loss: 0.9752  Accuracy: 63.54%\nEpoch [46/50]  Loss: 0.9748  Accuracy: 63.86%\nEpoch [47/50]  Loss: 0.9697  Accuracy: 63.70%\nEpoch [48/50]  Loss: 0.9698  Accuracy: 63.55%\nEpoch [49/50]  Loss: 0.9587  Accuracy: 64.21%\nEpoch [50/50]  Loss: 0.9564  Accuracy: 64.17%\n\nModel saved as emotion_cnn_resnet.pt\n","output_type":"stream"}],"execution_count":15}]}